{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理（NLP/Natural Language Processing)\n",
    "\n",
    "* 本周主要内容：自然语言处理（NLP）\n",
    "* 20春_API_人工智能与机器学习_week09\n",
    "*  电子讲义设计者：许智超，廖汉腾\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "# 本周内容介绍\n",
    "\n",
    "\n",
    "## 自然语言处理\n",
    "\n",
    "* 什么是自然语言处理[一分钟看懂自然语言处理](https://zhuanlan.zhihu.com/p/31157112)\n",
    "\n",
    "* 程序员的\"最强大脑\"[文言文编程](https://www.bilibili.com/video/BV1RJ411a7Qx?from=search&seid=433097907446745301)\n",
    "\n",
    "* 程序员吐槽大会[Python才是世界上最好的语言](https://www.bilibili.com/video/BV1yE411e7pS/?spm_id_from=333.788.videocard.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "/* 本电子讲义使用之CSS */\n",
       "div.code_cell {\n",
       "    background-color: #e5f1fe;\n",
       "}\n",
       "div.cell.selected {\n",
       "    background-color: #effee2;\n",
       "    font-size: 2rem;\n",
       "    line-height: 2.4rem;\n",
       "}\n",
       "div.cell.selected .rendered_html table {\n",
       "    font-size: 2rem !important;\n",
       "    line-height: 2.4rem !important;\n",
       "}\n",
       ".rendered_html pre code {\n",
       "    background-color: #C4E4ff;   \n",
       "    padding: 2px 25px;\n",
       "}\n",
       ".rendered_html pre {\n",
       "    background-color: #99c9ff;\n",
       "}\n",
       "div.code_cell .CodeMirror {\n",
       "    font-size: 2rem !important;\n",
       "    line-height: 2.4rem !important;\n",
       "}\n",
       ".rendered_html img, .rendered_html svg {\n",
       "    max-width: 100%;\n",
       "    height: auto;\n",
       "    float: center;\n",
       "}\n",
       "/* Gradient transparent - color - transparent */\n",
       "hr {\n",
       "    border: 0;\n",
       "    border-bottom: 1px dashed #ccc;\n",
       "}\n",
       ".emoticon{\n",
       "    font-size: 5rem;\n",
       "    line-height: 4.4rem;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* 本电子讲义使用之CSS */\n",
    "div.code_cell {\n",
    "    background-color: #e5f1fe;\n",
    "}\n",
    "div.cell.selected {\n",
    "    background-color: #effee2;\n",
    "    font-size: 2rem;\n",
    "    line-height: 2.4rem;\n",
    "}\n",
    "div.cell.selected .rendered_html table {\n",
    "    font-size: 2rem !important;\n",
    "    line-height: 2.4rem !important;\n",
    "}\n",
    ".rendered_html pre code {\n",
    "    background-color: #C4E4ff;   \n",
    "    padding: 2px 25px;\n",
    "}\n",
    ".rendered_html pre {\n",
    "    background-color: #99c9ff;\n",
    "}\n",
    "div.code_cell .CodeMirror {\n",
    "    font-size: 2rem !important;\n",
    "    line-height: 2.4rem !important;\n",
    "}\n",
    ".rendered_html img, .rendered_html svg {\n",
    "    max-width: 100%;\n",
    "    height: auto;\n",
    "    float: center;\n",
    "}\n",
    "/* Gradient transparent - color - transparent */\n",
    "hr {\n",
    "    border: 0;\n",
    "    border-bottom: 1px dashed #ccc;\n",
    "}\n",
    ".emoticon{\n",
    "    font-size: 5rem;\n",
    "    line-height: 4.4rem;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 百度API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A baidu_API准备工作 \n",
    "\n",
    "* 获取access_token等参数信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>refresh_token</th>\n",
       "      <td>25.029c7a505f7c479f0d727c8bab73a3ea.315360000....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expires_in</th>\n",
       "      <td>2592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_key</th>\n",
       "      <td>9mzdDoLvrnmvoIN0c/tl2W3KYcjqo5S8ojJPsi/S0NmG9F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>access_token</th>\n",
       "      <td>24.50c2b7412ec8650f43b1932c2902c9e8.2592000.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scope</th>\n",
       "      <td>public nlp_simnet nlp_wordemb nlp_comtag nlp_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_secret</th>\n",
       "      <td>497ecdfbd8a18406eeb5f4b26cb4390e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                0\n",
       "refresh_token   25.029c7a505f7c479f0d727c8bab73a3ea.315360000....\n",
       "expires_in                                                2592000\n",
       "session_key     9mzdDoLvrnmvoIN0c/tl2W3KYcjqo5S8ojJPsi/S0NmG9F...\n",
       "access_token    24.50c2b7412ec8650f43b1932c2902c9e8.2592000.15...\n",
       "scope           public nlp_simnet nlp_wordemb nlp_comtag nlp_d...\n",
       "session_secret                   497ecdfbd8a18406eeb5f4b26cb4390e"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'24.50c2b7412ec8650f43b1932c2902c9e8.2592000.1592462674.282335-19870489'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A-1 获取access_token等参数信息\n",
    "# encoding:utf-8\n",
    "# client_id 为官网获取的AK， client_secret 为官网获取的SK\n",
    "host = 'https://aip.baidubce.com/oauth/2.0/token?'\n",
    "params = {\n",
    "    \"grant_type\":\"client_credentials\",\n",
    "    \"client_id\":\"ZYvQ3jIzTNyoabk1roWvEGQL\",\n",
    "    \"client_secret\":\"t8hC3sldsjWcG15iWSafxgl9nQjOI2ma\"\n",
    "}\n",
    "response = requests.get(host,params=params)\n",
    "display(pd.json_normalize(response.json()).T)\n",
    "\n",
    "access_token=response.json()[\"access_token\"]\n",
    "access_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B 词法分析\n",
    "\n",
    "![](lexer.png)\n",
    "能够识别出文本串中的基本词汇（分词），对这些词汇进行重组、标注组合后词汇的词性，并进一步识别出命名实体\n",
    "\n",
    "* [百度API词法分析](https://ai.baidu.com/ai-doc/NLP/fk6z52f2u):\n",
    "    * 分词\n",
    "    * 词性标注\n",
    "    * 专名识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B-1 词法分析API测试\n",
    "def baidu_lexer(text):\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/nlp/v1/lexer?access_token=\"+access_token\n",
    "    data = {\n",
    "        \"text\" : text   \n",
    "    }\n",
    "    encode_data=json.dumps(data).encode('UTF-8')\n",
    "    headers = {\n",
    "        'Content-Type':'application/json'\n",
    "    }\n",
    "    return requests.post(url,encode_data).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8126659ff2b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcontent_lexer_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_lexer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"GBK\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# str转换dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcontent_lexer_dict\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# 表格化清晰展示词法分析结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_lexer_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"items\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'content_str' is not defined"
     ]
    }
   ],
   "source": [
    "content_lexer = baidu_lexer(text=\"百度是一家高科技公司\")\n",
    "\n",
    "# 二进制转换GBK\n",
    "content_lexer_str = str(content_lexer,encoding=\"GBK\")\n",
    "# str转换dict\n",
    "content_lexer_dict =json.loads(content_str)\n",
    "# 表格化清晰展示词法分析结果\n",
    "pd.json_normalize(content_lexer_dict[\"items\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C 词向量表示\n",
    "\n",
    "**通过词语的向量化来实现文本的可计算，帮助快速完成语义挖掘、相似度计算等应用**\n",
    "![](https://aip.bdstatic.com/portal/dist/1587554904644/ai_images/technology/nlp-word_embedding/introduce.png)\n",
    "\n",
    "\n",
    "* 语义召回\n",
    "    * 对候选资源进行词向量表示，并构建向量表示基础上的快速索引召回技术，与传统的基于字词倒排索引方法不同，直接从语义相关性角度上给用户召回结果\n",
    "    \n",
    "* 个性化推荐\n",
    "    * 基于用户的历史行为建模用户兴趣表示，学习用户与推荐候选之间的兴趣匹配度，实现对用户的个性化推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C-1 词向量表示API测试\n",
    "def baidu_word_emb_vec(text):\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/nlp/v2/word_emb_vec?access_token=\"+access_token\n",
    "    data = {\n",
    "        \"word\" : text   \n",
    "    }\n",
    "    encode_data=json.dumps(data).encode('UTF-8')\n",
    "    headers = {\n",
    "        'Content-Type':'application/json'\n",
    "    }\n",
    "    return requests.post(url,headers,encode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_id</th>\n",
       "      <th>word</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2313465727087719886</td>\n",
       "      <td>张飞</td>\n",
       "      <td>[-0.290384, -0.276273, 0.302719, 0.7209, 0.108...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                log_id word                                                vec\n",
       "0  2313465727087719886   张飞  [-0.290384, -0.276273, 0.302719, 0.7209, 0.108..."
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_word_emb_vec = baidu_word_emb_vec(\"张飞\")\n",
    "content_word_emb_vec = r_word_emb_vec.content\n",
    "content_word_emb_vec_str = str(content_word_emb_vec,encoding=\"GBK\")\n",
    "content_word_emb_vec_str_dict =json.loads(content_word_emb_vec_str)\n",
    "pd.json_normalize(content_word_emb_vec_str_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content_word_emb_vec_str_dict[\"vec\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D 词义相似度\n",
    "\n",
    "**通过词语向量化来计算两个词之间的相似度，满足高精度要求的业务场景需求**\n",
    "\n",
    "* 应用场景：\n",
    "    * 专名挖掘:\n",
    "        * 通过词语间语义相关性计算寻找人名、地名、机构名等词的相关词，扩大专有名词的词典，更好的辅助应用\n",
    "    * query改写:\n",
    "        * 通过寻找搜索query中词语的相似词，进行合理的替换，从而达到改写query的目的，提高搜索结果的多样性\n",
    "\n",
    "<br>\n",
    "</br>\n",
    "\n",
    "* 技术挖掘：\n",
    "    * 词向量决定高精度\n",
    "    * 词表收录\n",
    "    * 深度学习训练\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D-1  词义相似度API测试\n",
    "def baidu_word_emb_sim(word_1,word_2):\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/nlp/v2/word_emb_sim?access_token=\"+access_token\n",
    "    data = {\n",
    "        \"word_1\":word_1,\n",
    "        \"word_2\":word_2\n",
    "    }\n",
    "    encode_data=json.dumps(data).encode('UTF-8')\n",
    "    headers = {\n",
    "        'Content-Type':'application/json'\n",
    "    }\n",
    "    return requests.post(url,encode_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_id</th>\n",
       "      <td>1967551777399986382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.456862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words.word_2</th>\n",
       "      <td>上海</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words.word_1</th>\n",
       "      <td>北京</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "log_id        1967551777399986382\n",
       "score                    0.456862\n",
       "words.word_2                   上海\n",
       "words.word_1                   北京"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_word_emb_sim = baidu_word_emb_sim(\"北京\",\"上海\")\n",
    "content_word_emb_sim = r_word_emb_sim.content\n",
    "content_word_emb_sim_str = str(content_word_emb_sim ,encoding=\"GBK\")\n",
    "content_word_emb_sim_str_dict =json.loads(content_word_emb_sim_str)\n",
    "pd.json_normalize(content_word_emb_sim_str_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E DNN语言模型\n",
    "**判断一句话是否符合语言表达习惯，帮助您实现文本分析、纠错、对话等多种语义应用**\n",
    "![](dnnlm_cn.png)\n",
    "\n",
    "[百度API功能演示](https://ai.baidu.com/tech/nlp_basic/dnnlm_cn)\n",
    "\n",
    "* 应用场景：\n",
    "    * 拼写纠错\n",
    "        * 基于句子上下文，计算纠错候选的语言模型概率。用于拼写纠错，提升用户体验\n",
    "    * 对话系统\n",
    "        * 判断用户输入的句子是否符合自然语言表达习惯，辅助对话系统进行决策\n",
    "    * 机器翻译\n",
    "        * 语言模型对翻译候选的打分作为最终译文的重要排序指标，提升翻译效果\n",
    "        \n",
    "<br>\n",
    "</br>\n",
    "\n",
    "* 思考：\n",
    "    * 如何获取精准度？\n",
    "        * 基于超大规模的网页数据进行训练，可增强模型具备较高的准确度\n",
    "    * 可能用到的技术？\n",
    "        * 基于词向量和深度学习技术，可解决传统方法中的数据稀疏问题和维度灾难问题，模型泛化能力强，效果优\n",
    "    * （为什么有些小应用要免费给用户使用？获取用户信息和数据，以便于深度学习）\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baidu_dnnlm_cn(text):\n",
    "    url = \"https://aip.baidubce.com/rpc/2.0/nlp/v2/dnnlm_cn?access_token=\"+access_token\n",
    "    data = {\n",
    "        \"text\" : text   \n",
    "    }\n",
    "    encode_data=json.dumps(data).encode('UTF-8')\n",
    "    headers = {\n",
    "        'Content-Type':'application/json'\n",
    "    }\n",
    "    return requests.post(url,headers=headers,data=encode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_dnnlm_cn = baidu_dnnlm_cn(\"2016全国小考卷答题模板\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_id</th>\n",
       "      <td>4588494484419428878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>2016全国小考卷答题模板</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>items</th>\n",
       "      <td>[{'word': '2016', 'prob': 0.00377489}, {'word'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppl</th>\n",
       "      <td>1056.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "log_id                                4588494484419428878\n",
       "text                                        2016全国小考卷答题模板\n",
       "items   [{'word': '2016', 'prob': 0.00377489}, {'word'...\n",
       "ppl                                               1056.24"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_dnnlm_cn = r_dnnlm_cn.content\n",
    "content_dnnlm_cn_str = str(content_dnnlm_cn,encoding=\"GBK\")\n",
    "content_dnnlm_cn_str_dict =json.loads(content_dnnlm_cn_str)\n",
    "pd.json_normalize(content_dnnlm_cn_str_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '2016', 'prob': 0.00377489},\n",
       " {'word': '全国', 'prob': 0.00204963},\n",
       " {'word': '小', 'prob': 0.00228455},\n",
       " {'word': '考卷', 'prob': 1.68445e-05},\n",
       " {'word': '答题', 'prob': 0.000710084},\n",
       " {'word': '模板', 'prob': 0.00340623}]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_dnnlm_cn_str_dict[\"items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 产品经理如何绕开API的坑\n",
    "\n",
    "# 产品经理如何阅读API文档\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
